# ITPR anonymisation metric
<h2>Data anonymization</h2> 
<p>Anonymisation aims to preserving individualsâ€™ privacy while publishing/ processing data.</p> 
<p>The <b>reidentification</b> and <b>sensitive information inference</b> (such infering sickness, salary etc of an individual/ a group of individuals) risks of a dataset are important factors to consider when choosing the techniques and the parameters of the anonymization process. 
</p>
<p>Assessing these two risks correctly is the key to optimize the balance between <b>privacy</b> and <b>utility</b> of the dataset, as aggressive anonymization can yield useless data.</p>
<h2>Information theoretic-based privacy risk metric</h2>
Claims to be the only metric that can effectively quantify both:  
<li>Re-identification risk</li> 
<li>and sensitive information inference risk.</li> 
You can read more about it at the following link:
<p><b>Paper Link: </b>https://publications.polymtl.ca/9466/ </p>
<p><b>Metric Formula:</b>


</p>

![metric](https://github.com/chadha-sridi/Information-theoretic-based-privacy-risk-metric-implementation/assets/98777010/09917463-b7d0-4e8d-86ec-02ee3f9fde18)

In this repository, I provide the implementation code for this metric.
